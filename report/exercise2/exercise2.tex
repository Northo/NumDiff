\section{Heat equation in one dimension}
\label{heat-equation}
In this section, we consider the one-dimensional heat equation for $u = u(x, t)$, 
\begin{equation*}
    u_t = u_{xx}, \quad u(x, 0) = f(x), \quad x \in [0,1] := \Omega, 
    \label{eq:heat-eq}
\end{equation*}
with either Neumann or Dirchlet boundary conditions, 
and solve it numerically using both the Backward Euler method and Crank-Nicolson method. 
These are $\mathcal{O}(k+h^2)$ and $\mathcal{O}(k^2+h^2)$ methods respectively \cite{owren}, 
and we will analyze and compare their convergence using mesh refinement as we did in section \ref{task_1}. 
We will do refinement of the grids in both the $x$-direction and the $t$-direction, 
however we will here restrict our attention to uniform grids only. 

\subsection{Numerical solution method}
To solve the heat equation numerically we first perform semi-discretization, 
i.e. we do spatial discretization and keep the time continous. 
As in section \ref{task_1}, 
we divide the interval $\Omega$ into $M+2$Â equidistant nodes with separation $h=1/(M+1)$, 
so that we get a uniform grid with $M$ internal nodes and two boundary nodes. 
We then express the spatial derivative using the central finite difference to get 
\begin{equation*}
    u_t(x_m, t) = \frac{1}{h^2} \delta_x^2 u(x_m, t) + \mathcal{O}(h^2), 
    \quad m = 0,...,M+1.
\end{equation*}
We now introduce the single variate functions $v_m(t)$ as the approximation to $u(x_m, t)$, 
at each node $x_m$, 
turning the PDE into a set of ODEs 
\begin{equation*}
    \frac{dv_m(t)}{dt} = \frac{1}{h^2} \delta_x^2 v_m(t), 
    \quad v_m(0) = f(x_m). 
\end{equation*}

The problem is then generally solved by imposing the boundary conditions, 
and numerically integrating the equations in time, 
using for instance one of the many standard schemes for ODEs such as Euler's method. 
For the sake of convenience we employ the $\theta$-method, 
which for general ODEs $y' = g(y, t)$ is given as
\begin{equation*}
    y^{n+1} = y^n + \Delta t \left((1-\theta)g(y^n, t_n)+\theta g(y^{n+1}, t_{n+1})\right), 
\end{equation*}
and the value of $\theta$ determines the specific numerical scheme 
\begin{equation*}
\begin{split}
    \text{Forward Euler} \quad \theta = 0 \\
    \text{Backward Euler} \quad \theta = 1 \\
    \text{Crank-Nicolson} \quad \theta = \frac{1}{2}. \\
\end{split}
\end{equation*}
We use a constant time step $k = 1/(N-1)$, 
where $N$ denotes the number of time steps, 
and the final uniform grid is illustrated in figure\ref{fig:2-uniform-grid}. 
This gives the approximate solution of $v_m(t)$ at $t_n = nk$, 
where $n = 0, \ldots N-1$, 
and we denote the fully discretized approximation of $u(x_m, t_n)$ as $U_{m}^{n}$. 
After organizing the terms, 
the $\theta$-method for the 1D heat equation is then written out as
\begin{equation}
    (1 - \theta r \delta_x^2)U_m^{n+1} = \left(1 + (1-\theta)r\delta_x^2\right)U_m^n, 
    \label{eq:theta-heat}
\end{equation}
where we have defined $r=k/h^2$. 
In the following we will as mentioned consider the Backward-Euler and Crank-Nicolson methods. 
\begin{figure}[ht!]
    \centering
    \input{exercise2/grid_figure.pgf}
    \caption{Discrete uniform grid}
    \label{fig:2-uniform-grid}
\end{figure}

To impose Dirchlet boundary conditions, $u(0, t) = \sigma, \: u(1, t) = \beta$, 
we substitute $U_0^{n+1} = \sigma$ and $U_{M+1}^{n+1} = \beta$ in equation \eqref{eq:theta-heat} for $m=1$ and $m=M$ to obtain 
\begin{equation*}
\begin{split}
    (1+2r\theta)U_1^{n+1} - r\theta U_2^{n+1} = \left(1-2r(1-\theta)\right)U_1^n + r(1-\theta)U_2^n + r\sigma
    \quad (\text{for} \: m=1) \\
    (1+2r\theta)U_{M}^{n+1} - r\theta U_{M-1}^{n+1} = \left(1-2r(1-\theta)\right)U_{M}^n + r(1-\theta)U_{M-1}^n + r\beta
    \quad (\text{for} \: m=M), 
\end{split}
\end{equation*}
which we combine with equation \ref{eq:theta-heat} for the remaining spatial nodes to write the system of equations in matrix form
\begin{equation}
    (I - \theta r A)U^{n+1} = (I + (1-\theta)r A)U^n+\rho, 
    \label{eq:theta-heat-matrix}
\end{equation}
with 
\begin{equation}
    A = 
    \begin{bmatrix}
    -2 & 1 \\
    1 & -2 & 1 & \\
      & \ddots & \ddots & \ddots & \\
      &   & 1 & -2 & 1 \\
      &   &  & 1 & -2 \\
    \end{bmatrix}
    \quad \text{and} \quad
    \rho = 
    \begin{bmatrix}
        r\sigma \\ 0 \\ \vdots \\ 0 \\ r\beta
    \end{bmatrix}
    .
    \label{eq:theta-heat-matrix-dirchlet}
\end{equation}

For Neumann boundary conditions, $u_x(0, t) = \sigma, \: u_x(1, t) = \beta$, 
we introduce fictitious nodes at $m=-1$ and $m=M+2$, 
and approximate the first derivatives at the boundaries by
\begin{equation*}
    \frac{U_1 - U_{-1}}{2h} = \sigma
    \quad \text{and} \quad
    \frac{U_{M+2} - U_{M}}{2h} = \beta. 
\end{equation*}
We then use these expressions to eliminate the fictitious nodes from equation \eqref{eq:theta-heat} for $m=0$ and $m=M+1$ to get
\begin{equation*}
\begin{split}
    (1+2r\theta)U_0^{n+1} - 2r\theta U_1^{n+1} = \left(1-2r(1-\theta)\right)U_0^n + 2r(1-\theta)U_1^n - 2hr\sigma
    \quad (\text{for} \: m=0) \\
    (1+2r\theta)U_{M+1}^{n+1} - 2r\theta U_M^{n+1} = \left(1-2r(1-\theta)\right)U_{M+1}^n + 2r(1-\theta)U_M^n + 2rh\beta
    \quad (\text{for} \: m=M+1). 
\end{split}
\end{equation*}
Now we can write the system of equations on the same matrix form \eqref{eq:theta-heat-matrix}, 
but with 
\begin{equation}
    A = 
    \begin{bmatrix}
    -2 & 2 \\
    1 & -2 & 1 & \\
      & \ddots & \ddots & \ddots & \\
      &   & 1 & -2 & 1 \\
      &   &  & 2 & -2 \\
    \end{bmatrix}
    \quad \text{and} \quad
    \rho = 
    \begin{bmatrix}
        -2rh\sigma \\ 0 \\ \vdots \\ 0 \\ 2rh\beta
    \end{bmatrix}
    .
    \label{eq:theta-heat-matrix-neumann}
\end{equation}

Note that with Dirchlet conditions at both boundaries we only solve the equations for the internal spatial nodes $x_1 \dots x_M$ so that $A$ in \eqref{eq:theta-heat-matrix-dirchlet} is an $M \times M$ matrix. 
With Neumann conditions however we still need to solve for the boundary nodes, 
and $A$ is in \eqref{eq:theta-heat-matrix-neumann} an $(M+2) \times (M+2)$ matrix. 
In both cases though, all quantities on the right hand sides in \eqref{eq:theta-heat-matrix} are known, 
i.e. the equations are on the form $A\vec{x}=\vec{b}$, 
and the known $\vec{b}$ is just written via a matrix-vector product for notational convenience. 
To solve the problem we now solve this system of equations at each time step, 
and since matrices in both cases are tridiagonal, 
we represent them as sparse matrices and use a solver for sparse systems to save both memory and time. 

With the numerical schemes in hand we now solve the heat equation with the following Neumann boundary conditions and initial condition, 
\begin{equation}
    u_x(0,t) = u_x(1,t) = 0, \quad u(x,0) = 2\pi x - \sin(2\pi x). 
    \label{eq:2a}
\end{equation}
The computed solutions for $t \in [0, 0.5]$ is plotted in figure \ref{fig:task2-surface}, 
and qualitatively the solution behaves in accordance with what we expect for the heat equation. 
To quantify and compare the accuracy of the numerical schemes we will now proceed to analyze convergence using mesh refinement, 
similar to what we did in section \ref{task_1}. 

\begin{figure}
    \input{exercise2/surface_plot_combined.pgf}
    \caption{I am a surface plot, Hooray :)}
    \label{fig:task2-surface}
\end{figure}

\subsection{Convergence and mesh refinement}
As in section \ref{task_1} we now analyze the convergence of the numerical solution methods 
by doing mesh refinement of the spatial grid $x_m$. 
For \eqref{eq:2a}, the the analytical solution is not available in closed form, 
so in order to analyze convergence we compute a reference solution using a sufficiently high $M$, 
which we use in place of the analytical solution when computing the error. 
When doing mesh refinement of the spatial grid, 
we vary the number of spatial grid points $M$, 
and compute the numerical solution at the same point in time $t=t_{end}$. 
We keep the number of time steps $N$ fixed, 
so that the error from the time discretization does not vary, 
and compute the $L_2$ discrete and $l2$ continous relative errors with respect to the reference solution. 
The resulting convergence rates from the refinement is plotted in figure\ref{fig:2a-convergence}. 
\begin{figure}[ht]
    \centering
    \input{exercise2/2a_spatialref.pgf}
    \caption{Convergence plot, h refinement (2a)}
    \label{fig:2a-convergence}
\end{figure}

From figure\ref{fig:2a-convergence} we see that \textbf{comment about results}

In order to analyze the convergence further, 
we also consider the heat equation with a set of boundary and initial conditions for which the analytical solution is known. 
Specifically we consider 
\begin{equation}
    u(0,t) = u(1,t) = 0, \quad u(x,0) = \sin(\pi x), 
    \label{eq:2b-manufactured}
\end{equation}
on the same domain $x \in [0,1] := \Omega$ and $t > 0$. 
Note that we now have Dirchlet boundary conditions, 
and we are now able compute the analytical solution, 
which we do using the method of sepparation of variables. 
\\ \textbf{Skal skrive sepparasjon her da}
\begin{equation}
    u(x,t) = \sin(\pi x)  e^{- \pi^2 t}.
\end{equation}

We now do the same spatial refinement for equation \eqref{eq:2b-manufactured}, 
however now we compute the errors with respect to the analytical solution. 
The resulting convergence plots are shown in figure \ref{fig:2b-spatial-ref}, 
and here the difference between Backward Euler and Crank-Nicolson becomes more apparent. 
Both methods are second order in the spatial step $h$, 
and are unconditionally stable \cite{find some source probably brynjulf}, 
unlike e.g. the explicit Forward Euler method ($\theta=0$). 
Crank-Nicolson is however one order higher in the time step $k$, 
so that the total error is lower for Crank-Nicolson than Backward-Euler when $M$ and $N$ are the same. 
This is seen when refining the spatial step $h$; 
at large $h$ (low $M$), 
the error is dominated by the spatial error, 
and as we decrease $h$ (increase $M$) we should see the expected second order convergence in the spatial step. 
At some point, 
when the spatial error has become sufficiently small, 
the total error will be dominated by the error in the time step $k$, 
and we expect this to happen earlier for the Backward-Euler method. 
In figure \ref{fig:2b-spatial-ref} we see exactly this. 
The error of the Crank-Nicolson solution with $N=10000$ exhibits second order convergence throughout the entire refinement, 
but when lowering the number of time steps to $N=1000$, 
the time step error starts to dominate towards the end of the refinement and the error curve flattens. 
For the solution computed with the Backward-Euler method we see the flattening happening much earlier, 
which is due to this method being less accurate in time. 
\begin{figure}
    \centering
    \label{fig:2b-spatial-temporal-ref}
    \subfloat[Convergence plot, h refinement (2b)]{
        \input{exercise2/2b_spatialref.pgf}
    } \\
    \subfloat[Convergence plot, t refinement (2b)]{
        \input{exercise2/2b_temporalref.pgf}
    }
\end{figure}

Now we proceed to do refinement in the $t$-direction. 
As mentioned, Crank-Nicolson

%\begin{figure}[ht]
%    \centering
%    \input{exercise2/2b_kchref.pgf}
%    \caption{Convergence plot, kch refinement (2b)}
%    \label{fig:2b-kch-ref}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: AMR data is likely to change.
% Luckily, that isn't a big problem, as pgfplots is brilliant.

% Seriously. It's glorious.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%        ,,,,,             pgfplots
%       ////""\               .
%      (((/ m m              -|-                        __
%      )))c  = )              |                        (__)
%     ////-./~`    .                                    []
%    (((( `.`\    ::                                    []
%     )))`\ \)).-;.'                           .------, []
%      (() `._.-'`                           _(        )[]
%      )/ `. |  .'`^^^^^^^^^^^^^^^^^^^^^^^^^^))\`.----'`[]
%jgs   (    \' { ~ - ~~ _  ~  -  ~~  - ~  - ((  | |     []
%  .-.--\    \ {                             )) | |     []
%  |_;_._`\   |{                            ((__|_|-----[]
% |  ;   ```  ;{                             ))         []
% | /``-.____/ `~~~[]~~~~~~~~~~~~~~~~~~~~~~~'-'         []
% `'              (__)                                 (__)
%\begin{figure}[ht]
%    \centering
%    \input{exercise2/2b_AMR_combined.pgf}
%\end{figure}

\section{Invicid Burgers' equation}

In this section we turn to solve the inviscid Burgers' equation with given Dirchlet boundary conditions and initial condition
\begin{equation}
    u_t = -uu_x, \quad u(0, t) = u(1, t) = 0, \quad u(x, 0) = exp(-400(x-1/2)^2).
    \label{eq:burger}
\end{equation}
This equation exhibits breaking; 
after some point in time $t_b$ the solution breaks, 
and the unique solution does not exist, 
leading to the formation of a \textit{shock wave}.\cite{burgers} 
The time $t_b$ before this can happen is given by
\begin{equation}
% I am not sure if this is the exact time of breaking or just the earliest possible breaking time. 
    t_b = \frac{-1}{min f'(x)}, 
    \label{eq:t_break}
\end{equation}
where $f(x)$ is the given initial condition $u(x, 0) = f(x)$.\cite{burgers} 

\subsection*{Numerical solution method}
To solve \eqref{eq:burger} numerically we perform semidiscretization in the same way as we did for the heat equation in section \ref{heat-equation}, 
also on a uniform spatial grid as described in section \ref{task_1}. 
The resulting system of ODEs is
\begin{equation*}
    \frac{\partial v_m}{\partial t} = -v_m \frac{1}{2h} (v_{m+1} - v_{m-1}). 
\end{equation*}
We impose the Dirchlet boundary conditions and integrate the ODEs using \textit{solve\_ivp} from the SciPy library, 
with the default explicit Runge-Kutta method of order 4(5)\cite{solve_ivp}. \\
\textbf{Comment/question:} Is it fine to use scipy.integrate.solve\_ivp, 
or should it be all home cooking? 

\subsection{Time of breaking}
Insertion of $u(x, 0)$ for $f$ in \eqref{eq:t_break}, 
gives $t_b \approx 0.058$. 
To get a criterion for when the numerical solution has broken down, 
we use that the stable solution should be strictly increasing from $x=0$ to towards the apex, 
and then strictly decreasing from the apex towards the right boundary at $x=1$. 
When this is no longer the case we say that the solution has broken, 
and the time for which this happened for our solution was at $t^* \approx 0.055$. 
Figure \ref{fig:burgers-samples} shows the solution sampled around the time of breaking. 
% Not sure what to make of this result, also varying M seems to affect 
% the breaking time. I made a function wich calculates the :

\begin{figure}[ht]
    \centering
    \input{exercise2/2c_samples.pgf}
    \caption{Numerically computed solution to the Invicid Burgers' equation around the time of breaking.}
    \label{fig:burgers-samples}
\end{figure}
