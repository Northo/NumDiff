\section{Laplace equation in two dimensions}
In this section, we will solve the two-dimensional Laplace equation on a quadratic domain
\begin{equation}
    u_\text{xx} + u_\text{yy} = 0, \, (x,y) \in \Omega := [0,1]^2,
    \label{ex3:eq:laplace}
\end{equation} with boundary conditions on the edges of $\Omega$
\begin{equation}
    \begin{split}
        u(0,y) &= 0,\\
        u(1,y) &= 0,\\
        u(x,0) &= 0,\\
        u(x,1) &= \sin(2\pi x).\\
    \end{split}
    \label{ex3:eq:boundary_conditions}
\end{equation}
We will solve this equation numerically using a five point stencil, but first, we solve it analytically to provide a reference solution which can be compared with the numerical one.

\subsection{Analytical solution}

The solution of equation \ref{ex3:eq:laplace} can be found by separation of variables.
First, asssume that we can write
\begin{equation*}
    % I used these names, but I think it's more common with capital X and Y or something.
    % I'm open for discussions of this.
    u(x,y) = \alpha(x) \beta(y),
\end{equation*}
which implies that
\begin{equation*}
    u_\text{xx} + u_\text{yy} =  \alpha''(x) \beta(y) + \alpha(x) \beta''(y) = 0,
\end{equation*}
where the prime markers $'$ denote differentiation of the single variable functions $\alpha(x)$ and $\beta(y)$.
Rearranging, we get that
\begin{equation*}
    \frac{\alpha''(x)}{\alpha(x)} = \frac{\beta''(y)}{\beta(y)} = c
\end{equation*}
must be constant, since $\alpha$ and $\beta$ are functions of indepentent variables.
Thus, we have two second order differential equations
\begin{equation*}
    \begin{split}
        \alpha''(x) - c\alpha(x) &= 0, \\
        \beta''(x) - c\beta(x) &= 0,
    \end{split}
\end{equation*}
with boundary conditions
\begin{equation*}
    \begin{split}
    \alpha(0) = \alpha(1) = \beta(0) = 0,\\
    \alpha(x)\beta(1) = \sin(2\pi x).
    \end{split}
\end{equation*}

Setting $\beta(1)$ to $1$ yields $\alpha(x) = \sin(2\pi x)$, so that $\alpha''(x) = -4\pi^2\alpha(x)$ where $y = 1$, we find that $c = -4\pi^2$.
Solving the equation for $\beta(y)$, we find that
\begin{equation*}
    \beta(y) = b_1 e^{\sqrt{c} y} + b_2 e^{-\sqrt{c} y}.
\end{equation*}
Inserting $c = 4\pi$ and the boundary condtitions $\beta(0) = 0$ and $\beta(1) = 1$, we get
\begin{equation*}
    \beta(y) = \frac{\sinh(2\pi y)}{\sinh(2\pi)},
\end{equation*}
and finally
\begin{equation*}
    u(x,y) = \frac{\sin(2\pi x) \cdot \sinh(2\pi y)}{\sinh(2\pi)}.
\end{equation*}

\subsection{Numerical solution}
\label{sec:exc3:numerical}
We solve the equation numerically by discretizing the domain $\Omega = [0, 1]^2$, approximate the equation on that domain using a five point stencil, and solving the approximated system.
The domain is discretized with $M+2$ and $N+2$ points in the $x$ and $y$ direction, so that there are $M$ and $N$ internal points in each direction.
The total system to be solved is thus $M \times N$ points, as the boundaries are known.

Rewriting Laplace's equation using central differences, we get
\begin{equation*}
    \begin{split}
    % TODO: What do you people think about this notation?
    % I think the equations are a bit long, but relatively clear in return.
    \partial^2_x u(x_m, y_n) 
        &= \frac{1}{h^2}[u(x_{m-1},y_n) + 2u(x_m,y_n) + u(x_{m+1},y_n)] + \Oh(h^2)\\
        &= \frac{1}{h^2}\delta^2_x u(x_m,y_n) + \Oh(h^2),\\
    \end{split}
\end{equation*}
\begin{equation*}
    \begin{split}
    \partial^2_y u(x_m, y_n) 
        &= \frac{1}{k^2}[u(x_\text{m},y_{n-1}) + 2u(x_m,y_n) + u(x_\text{m},y_{n+1})] + \Oh(k^2)\\
        &= \frac{1}{k^2}\delta^2_y u(x_m,y_n) + \Oh(k^2),\\
    \end{split}
\end{equation*}
where $(x_m, y_n)$ denote the point $(m,n)$ in the grid. 
%$i = 0,\ldots M_x$, and $j = 0,\ldots, M_y$.
Adding these expressions, and naming our approximated solution with the shorthand notation $U_m^n := u(x_m,y_n)$, we find that the Laplace equation can be approximated 
\begin{equation*}
    0 = \partial^2_x u(x_m,y_n) + \partial^2_y u(x_m,y_n)
    \approx \frac{1}{h^2}\delta^2_x U_m^n + \frac{1}{k^2}\delta^2_y U_m^n,
\end{equation*}
or, simplifying the notation with the notation visualized in figure \ref{ex3:fig:stencil},
\begin{equation*}
    \frac{1}{k^2}(U_\text{above} + U_\text{below} - 2U_\text{center}) + \frac{1}{h^2}(U_\text{left} + U_\text{right} - 2U_\text{center}) = 0.
\end{equation*}

\begin{figure}[htb]
    \centering
    \input{./exercise3/stencil.pgf}
    \caption{The five-point stencil corresponding to central difference differentiation in both the $x$- and $y$-direction.}
    \label{ex3:fig:stencil}
\end{figure}

%This stencil can be used to approximate the value of $U(x_m, y_n) = U_\text{center}$ for all points $(x_m, y_n)$ in the grid.
We will now construct the matrix $A$ such that we can write our equation as the matrix equation $A U = b$, where $U$ is the flattened solution, and $b = \vec{b}$ contains the boundary conditions of the system, which will be explained in more detail below.
Ignoring firstly the above and below nodes of the stencil, we can easily set up a matrix $A'$ in the same way as in Section \ref{task_1}.
Note that this is done only in order to clarify the derivation -- the matrix $A'$ is merely a "stepping stone" -- not a useful result.
\begin{equation*}
    %\renewcommand{\arraystretch}{2.5} % stretch matrix vertically to make it square
    A'U = \frac{1}{h^2}
    \begin{bmatrix}
    -2& 1 \\
    1 & -2 & 1 &   \\
      & \ddots & \ddots & \ddots & \\
      %&   & 1 & -2 & 1 \\
      &   & 1 & -2 & 1 \\
      &   &  & 1 & -2 \\
    \end{bmatrix}
    \begin{bmatrix}
    U_1^n \\ U_2^n \\ \vdots \\ U_{M-1}^n \\ U_M^n \\
    \end{bmatrix}
    =
    \begin{bmatrix}
    b_1 \\ b_2 \\ \vdots \\ b_{M-1}^n \\ b_M^n \\
    \end{bmatrix}
    ,
    \label{ex3:eq:simple_matrix}
\end{equation*}
Note also that this equation only considers one particular value of $y$, corresponding to $n$.
The boundary conditions on the right hand side are zero for all internal points, while the values along the edges, that is $n = {1, N}$ or $m = {1, M}$, are set according to \eqref{ex3:eq:boundary_conditions}.

In order to actually solve our entire system, we must include the nodes above and below the center as well.
This can be done by considering a much larger matrix $A$ and a much longer vector $U$.
The latter being a stacked vector containing all $M$ elements $U_1^1, \ldots, U_M^1$, followed by $U_1^2, \ldots U_M^2$ and so on.
%% The matrix $A$ is still the tridiagonal matrix sith elements $[1, -4, 1]$, but now with size $(N\cdot M)^2$.
%% Now, we are able to inclute the nodes $U_\text{above}$ and $U_\text{below}$ from the stencil.
In this formulation of the problem, the values $U_\text{right}$ and $U_\text{left}$ correspond to the neighbouring points in $U$.
The above and below nodes -- instead of being above and below $U_\text{center}$ -- are now to the sides, $M$ nodes away, as illustrated in figure \ref{ex3:fig:flat_stencil}.

\begin{figure}[htb]
    \centering
    \input{./exercise3/flat_stencil.pgf}
    \caption{By flattening the five-point stencil, we can write the system of equations, which is then on the form $AU = 0$.}
    \label{ex3:fig:flat_stencil}
\end{figure}

We thus write
\begin{equation*}
    \renewcommand{\arraystretch}{2.5} % stretch matrix vertically to make it square
    % This matrix doesn't look good. We could divide it, or give the elements names (e.g. a, b, c),
    % or keep things like this. I don't know what's best.
    AU = 
    \begin{bmatrix}
        \frac{-2}{h^2} + \frac{-2}{k^2} & \frac{1}{h^2} &&\frac{1}{k^2}\\
        \frac{1}{h^2} & \frac{-2}{h^2} + \frac{-2}{k^2}   & \frac{1}{h^2} &&\frac{1}{k^2}\\
        & \frac{1}{h^2} & \frac{-2}{h^2} + \frac{-2}{k^2}   & 0 &&\frac{1}{k^2}\\
        &  \quad \ddots & \quad \ddots  & \quad \ddots \\
        \frac{1}{k^2} && 0 & \frac{-2}{h^2} + \frac{-2}{k^2} & \frac{1}{h^2} \\
        & \frac{1}{k^2} && \frac{1}{h^2} & \frac{-2}{h^2} + \frac{-2}{k^2}   & \frac{1}{h^2} \\
        && \frac{1}{k^2} && \frac{1}{h^2} & \frac{-2}{h^2} + \frac{-2}{k^2} \\
    \end{bmatrix}
    \begin{bmatrix}
    U_\text{1} \\ \vdots \\ U_\text{m} \\ \vdots \\ U_{N \times m} \\ \vdots \\ U_{N \times M} \\
    \end{bmatrix}
    =
    \begin{bmatrix}
    b_1 \\ \vdots \\ b_m \\ \vdots \\ b_{N \times m} \\ \vdots \\ b_{N \times M}\\
    \end{bmatrix}
    = b,
    \label{ex3:eq:solution_equation}
\end{equation*}
which can be solved.
It is important to note the zeros on the upper and lower diagonal, which correspond to the nodes that have less than four neighbours, ie. the nodes on the border.
These nodes are treated with the boundary conditions from $b$, whose values are set in points corresponding to the borders of the system, as mentioned above.
%Given initial conditions on the boundary $\partial\Omega$, these may easily be incorporated by adding them as an inhomogenity.
Thus, the final equation will be on the form $AU = b$, where $b$ and $U$ are flattened matrices, i.e. vectors, of length $N \times M$, while $A$ is a matrix of size $(N \times M)^2$
%\todo{Should probably be explained in more detail?}

The large matrix $A$ is also showed in a more managable way in figure \ref{fig:laplace:stencil}, where it is plotted as a heatmap.
By noticing its recursive structure, one may realize that the matrix can be constructed by a Kronecker sum.
This procedure is discussed in more depth in \ref{sec:PDE} where the Biharmonic equation is solved using the fast Poisson solver.
For now however, we will only take the observation about the Kronecker sum as a convenient way to implement the construction of our matrix.
Let $K_M$ be the system matrix of the one dimensional finite central difference scheme of size $m$ introduced as $A'$ in equation \eqref{ex3:eq:simple_matrix}.
That is, the $M\times M$ matrix
$$
K_M =
\begin{bmatrix}
  -2& 1 \\
  1 & -2 & 1 &   \\
  & \ddots & \ddots & \ddots & \\
  %&   & 1 & -2 & 1 \\
  &   & 1 & -2 & 1 \\
  &   &  & 1 & -2 \\
\end{bmatrix}.
$$
The full matrix $A$ is then compactly written as
\begin{equation}
  A =
  \frac{1}{h^2} K_N \oplus \frac{1}{k^2} K_M
  = \frac{1}{h^2} K_N \otimes I_M
  + I_N \otimes \frac{1}{k^2} K_M.
\end{equation}
This matrix is colorfully illustrated in figure \ref{fig:laplace:stencil}.

    %% sp.kron(Ky, sp.eye(Nx))/hx**2
    %% + sp.kron(sp.eye(Ny), Kx)/hy**2
\begin{figure}[btp]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
        width=8cm, height=8cm,
        xmin=0, xmax=20,
        ymin=0, ymax=20,
        ticks=none,
        y dir=reverse,
        colormap/blackwhite,
        colorbar,
      ]
      \addplot[
        surf,
        mesh/cols=21,
        point meta=explicit,
        shader=flat corner,
      ] 
      table[meta=U]{./exercise3/stencil.dat};
      \draw[dashed] (4,4) rectangle (8, 8);
    \end{axis}
  \end{tikzpicture}

  \caption{The five point stencil matrix for the case $M=4$, $N=5$. Notice the recursive structure.}
  \label{fig:laplace:stencil}
\end{figure}

Using this method, the solution to equation \ref{ex3:eq:laplace} is computed, and the results are shown in figure \ref{ex3:fig:heat_map}.
An error analysis showing the error with varying grid resolutions in both the $x$- and the $y$-direction is presented in \ref{ex3:fig:convergence_plot}.

\begin{figure}[tbp]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            colorbar,
            view={0}{90},
            colormap/jet,
            mesh/ordering=x varies,
            mesh/cols=100,
            mesh/rows=100,
            xlabel=x,
            ylabel=y,
        ]
            \addplot[
                surf,
                shader=flat,
                point meta=explicit,
            ] 
            table[meta=U]{./exercise3/laplace_uniform.dat};
        \end{axis}
    \end{tikzpicture}
    \caption{The numerically computed solution to the Laplace equation, using $N = M = 100$.}
    \label{ex3:fig:heat_map}
\end{figure}

\begin{figure}[tbp]
    \centering
    \input{exercise3/convergence.pgf}
    \caption{Convergence plot for varying $N$ and $M$.}
    \label{ex3:fig:convergence_plot}
\end{figure}
